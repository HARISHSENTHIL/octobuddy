wakeword:
  model_path: "./models/Hey_octobuddy.onnx"  # Relative path for Ubuntu
  backend: "onnx"   # Ubuntu: onnx with Speex support
  enable_speex_noise_suppression: true  # Ubuntu advantage: built-in noise suppression
  threshold: 0.005  # Wake word detection threshold
whisper:
  bin: "./whisper.cpp/build/bin/whisper-cli"  # Ubuntu path
  model: "./whisper.cpp/whisper.cpp/models/ggml-base.en.bin"
piper:
  model: "./models/en_US-lessac-medium.onnx"
  config: "./models/en_US-lessac-medium.onnx.json"
cloud:
  mode: "llama"         # "llama" | "openai" | "off"
  llama_url: "http://127.0.0.1:11434/api/generate"  # Updated for Ollama
  model: "llama3.2:3b"  # Default model
cache:
  file: "cache.json"
  max_items: 200
safety:
  blocked_terms: ["kill", "violence", "gun", "suicide", "sex"]
audio:
  sample_rate: 16000
  channels: 1
  blocksize: 512
  enable_speex: true  # Ubuntu advantage
  input_device_index: 5  # Device that supports 16kHz
  fallback_sample_rate: 48000  # Fallback if 16kHz not supported
